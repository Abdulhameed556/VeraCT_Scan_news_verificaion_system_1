{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a VeraCT Scan-Like Fake News Detection System with RAG\n",
    "\n",
    "We'll structure the system to ensure accurate, real-time fact verification by retrieving and analyzing credible sources. Here's the roadmap:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1Ô∏è‚É£ Understanding the Core System Components**\n",
    "\n",
    "A VeraCT Scan-like system has three major steps:\n",
    "\n",
    "- Fact Extraction ‚Äì Identify key claims in the news article.\n",
    "- Information Retrieval ‚Äì Search for corroborating/conflicting sources (using RAG).\n",
    "- Fact Verification & Reasoning ‚Äì Compare retrieved evidence and determine credibility.\n",
    "\n",
    "2Ô∏è‚É£ System Architecture Breakdown\n",
    "\n",
    "Your system will have the following key modules:\n",
    "\n",
    "\n",
    "- `News Ingestion`-->\tUsers submit news articles for fact-checking\n",
    "- `Fact Extraction`-->\tExtract key claims using NLP\n",
    "- `Retrieval-Augmented Generation (RAG)`-->\tSearch the web for supporting/opposing evidence\n",
    "- `Source Credibility Analysis`-->\tAssess trustworthiness of retrieved sources\n",
    "-`Evidence Aggregation & Decision`-->\tCompare claims with retrieved evidence to classify as TRUE, FALSE, or MIXED\n",
    "- `User Interface (Web App)`-->\tShow results visually, provide reasoning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Extracting Key Claims from News Articles**\n",
    "\n",
    "`Goal`\n",
    "\n",
    "We need to extract key claims (who, what, where, when) from a news article using Named Entity Recognition (NER) and keyword extraction.\n",
    "\n",
    "**Tools We'll Use:**\n",
    "\n",
    "- ‚úÖ spaCy (for NER)\n",
    "- ‚úÖ KeyBERT (for keyword extraction)\n",
    "- ‚úÖ TextRank (for summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Elon Musk', 'PERSON'), ('Tesla', 'ORG'), ('Nigeria', 'GPE'), ('thousands', 'CARDINAL'), ('Nigerian', 'NORP')]\n",
      "keywords: [('tesla build', 0.6023), ('factory nigeria', 0.5619), ('announced tesla', 0.4734), ('tesla', 0.4663), ('nigeria creating', 0.4631)]\n",
      "Summary: Elon Musk announced that Tesla will build a new factory in Nigeria,\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from keybert import KeyBERT\n",
    "from summa import summarizer\n",
    "\n",
    "# Load spaCy model for Named Entity Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample news article\n",
    "news_article = \"\"\"Elon Musk announced that Tesla will build a new factory in Nigeria,\n",
    "creating thousands of jobs. The Nigerian government confirmed this deal.\"\"\"\n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£ Extract Named Entities\n",
    "doc = nlp(news_article)\n",
    "entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "print(\"Named Entities:\", entities)\n",
    "\n",
    "# 2Ô∏è‚É£ Extract Keywords using KeyBERT\n",
    "kw_model = KeyBERT()\n",
    "keywords = kw_model.extract_keywords(news_article, keyphrase_ngram_range=(1,2), stop_words='english')\n",
    "print(\"keywords:\", keywords)\n",
    "\n",
    "# 3Ô∏è‚É£ Summarize the article using TextRank\n",
    "summary = summarizer.summarize(news_article, ratio=0.5)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'Elon Musk announced that Tesla will build a new factory in Nigeria, creating thousands of jobs. The Nigerian government confirmed this deal.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a summarization model to extract key claims\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "news_article = \"\"\"Elon Musk announced that Tesla will build a new factory in Nigeria, \n",
    "                  creating thousands of jobs. The Nigerian government confirmed this deal.\"\"\"\n",
    "\n",
    "summary = summarizer(news_article, max_length=30, min_length=15, do_sample=False)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helps extract key claims from the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîπ Step 2: Searching the Web for Supporting Evidence (RAG)**\n",
    "\n",
    "We use search APIs to find supporting or conflicting news reports.\n",
    "\n",
    "üìå Free Search APIs you can use:\n",
    "- Brave Search API (Privacy-focused, free)\n",
    "- DuckDuckGo API (Free, but limited)\n",
    "- Google Search API (Paid but powerful)\n",
    "- Bing Search API (Better for enterprise use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (0.3.46)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-community) (2.2.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"title\": \"List of Tesla factories - Wikipedia\", \"link\": \"https://en.wikipedia.org/wiki/List_of_Tesla_factories\", \"snippet\": \"<strong>Tesla</strong>, Inc. operates plants worldwide for the manufacture of their products, including electric vehicles, lithium-ion batteries, solar shingles, chargers, automobile parts, manufacturing equipment and tools for its own <strong>factories</strong>, as well as a lithium ore refinery. Maxwell continued to operate as subsidiary until 2021. Due to the short holding time and no known products produced under Tesla, their production facilities are not listed above. ^ The eleventh character of the vehicle identification number (VIN) indicates the factory the car has been built in.\"}, {\"title\": \"Tesla Gigafactory: Locations, Cost, Future, Electricity - Business Insider\", \"link\": \"https://www.businessinsider.com/tesla-gigafactory\", \"snippet\": \"Here&#x27;s a look at <strong>Tesla</strong>&#x27;s Gigafactory network and the expansion plans for the facilities that produce batteries for the company&#x27;s electric vehicles. Tesla currently has six massive Gigafactories located in Fremont, California; Sparks, Nevada; Berlin, Germany; Shanghai, China; Austin, Texas; and Buffalo, New York.  \\u00b7 In March of 2023, Tesla confirmed plans to build a Gigafactory in Mexico. The plant will sit in the industrial hub of Monterrey. After initially lauding the addition of a Mexico factory, Tesla has pumped the brakes on the project amid a tougher electric vehicle market. In Berlin, Tesla currently builds 6,000 cars per week. It took the company a year to reach the 5,000 car-per-week milestone. It's a model Tesla's set to copy for new factories and helps support the company's goals of 25,000 cars per year per factory. There are already six gigafactories around the globe where Tesla builds its Model S, Model X, Model Y, and Model 3 vehicles as well as the Cybertruck. A seventh, Tesla's first factory in Mexico, is also in the works, and more are likely to come as Tesla's sales volume increases. Tesla's Nevada factory is where it will eventually produce the Tesla 18-wheeler Semi, thanks to a $3.6. billion investment it announced in 2023. Right now, the Gigafatory produces batteries and electric motors. Tesla's Berlin Gigafactory, which opened in 2022, manufactures battery cells and has a capacity for over 375,000 Model Y cars per year.  \\u00b7 In Shanghai, China, Tesla builds Model 3 and Y cars, with capacity to ship more than 950,000 cars annually, up from an original capacity of 750,000 vehicles.\"}, {\"title\": \"Manufacturing | Tesla\", \"link\": \"https://www.tesla.com/manufacturing\", \"snippet\": \"Engineers, production associates and safety professionals work to make <strong>Tesla</strong> the world\\u2019s most advanced manufacturer. Learn more about manufacturing at <strong>Tesla</strong>. Tesla's first factory\\u2014produces Model S, Model 3, Model X and Model Y \\u00b7 See Jobs \\u00b7 Gigafactory Nevada \\u00b7 One of the world's highest volume plants for electric motors, batteries and powertrains \\u00b7 One of the world's highest volume plants for electric motors, batteries and powertrains \\u00b7 See Jobs \\u00b7 Gigafactory New York \\u00b7 Builds Solar Roof, solar panels and electrical components for Superchargers \\u00b7 Builds Solar Roof, solar panels and electrical components for Superchargers \\u00b7 See Jobs \\u00b7 Gigafactory Shanghai \\u00b7 Tesla's first factory abroad\\u2014produces Model 3 and Model Y \\u00b7 Tesla's first factory abroad\\u2014 produces Model 3 and Model Y \\u00b7 See Jobs \\u00b7 Gigafactory Texas \\u00b7 Tesla\\u2019s new global headquarters produces Model Y and is the future home of Cybertruck \\u00b7 Tesla is an Equal Opportunity employer. All qualified applicants will receive consideration for employment without regard to any factor, including veteran status and disability status, protected by applicable federal, state or local laws. In 2012, the first Model S rolled off the assembly line at our factory in Fremont, California.\"}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import BraveSearch\n",
    "\n",
    "# Replace this with your actual Brave API key\n",
    "api_key = \"BRAVESEARCH_API_TOKEN\"\n",
    "\n",
    "# Initialize BraveSearch correctly\n",
    "search = BraveSearch.from_api_key(api_key=api_key, search_kwargs={\"count\": 3})\n",
    "\n",
    "query = \"Tesla building new factory in Nigeria\"\n",
    "\n",
    "# Perform the search\n",
    "results = search.run(query)\n",
    "\n",
    "# Print the search results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üö® Verdict: The News About Tesla in Nigeria Is Fake**\n",
    "\n",
    "Your search results show no credible sources reporting that Tesla is building a factory in Nigeria. Instead, all sources (Wikipedia, Business Insider, and Tesla‚Äôs official site) confirm Tesla's current and planned factory locations, which include:\n",
    "\n",
    "‚úÖ Existing Gigafactories:\n",
    "\n",
    "    - Fremont, California\n",
    "\n",
    "    - Sparks, Nevada\n",
    "\n",
    "    - Berlin, Germany\n",
    "\n",
    "    - Shanghai, China\n",
    "\n",
    "    - Austin, Texas\n",
    "\n",
    "    - Buffalo, New York\n",
    "\n",
    "‚úÖ Planned Factory:\n",
    "\n",
    "    - Mexico (Monterrey)\n",
    "\n",
    "‚ùå No mention of Nigeria or any African country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üîç Next Step: Fake News Detection**\n",
    "\n",
    "Now, let's finalize this by running a fake news classifier. You already have NER, keyword extraction, and summarization. Next, let's check if this news is likely fake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9983853101730347}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a sentiment analysis model\n",
    "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "news_text = \"Elon Musk announced that Tesla will build a new factory in Nigeria, creating thousands of jobs. The Nigerian government confirmed this deal.\"\n",
    "\n",
    "result = classifier(news_text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using huggingface token: Load the Model with Your API Token**\n",
    "\n",
    "Now, modify your code to authenticate and load the DeBERTa-v3-MNLI model correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "8+9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\VeraCT Scan-Like Fake News Detection System\\RAG\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'Elon Musk announced that Tesla will build a new factory in Nigeria, creating thousands of jobs. The Nigerian government confirmed this deal.', 'labels': ['real news', 'fake news'], 'scores': [0.990280032157898, 0.009720000438392162]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads from .env file\n",
    "login(token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))  # now it's secure\n",
    "\n",
    "\n",
    "# Use an alternative model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "news_text = \"Elon Musk announced that Tesla will build a new factory in Nigeria, creating thousands of jobs. The Nigerian government confirmed this deal.\"\n",
    "\n",
    "# Define candidate labels\n",
    "labels = [\"real news\", \"fake news\"]\n",
    "\n",
    "# Perform classification\n",
    "result = classifier(news_text, candidate_labels=labels)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (1.68.2)\n",
      "Requirement already satisfied: tiktoken in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\veract scan-like fake news detection system\\rag\\myenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verified News: Found in reliable sources\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import spacy\n",
    "\n",
    "# Load NLP model for named entity recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# News article to verify\n",
    "news_text = \"\"\" Nigerian governors‚Äô forum breaks silence on Fubara‚Äôs suspension\n",
    "\n",
    "Tolulope Popoola\n",
    "\n",
    "March 22, 2025\n",
    "Nigerian Governors‚Äô Forum\n",
    "Share\n",
    "\n",
    "The Nigeria Governors‚Äô Forum (NGF) has defended its decision to remain silent on recent political events, emphasizing its role as a neutral policy body.\n",
    "\n",
    "In a statement issued on Saturday, titled ‚ÄúNGF Clarifies Silence on Political Matters,‚Äù the forum explained that taking positions on partisan issues could divide its members, who belong to different political platforms.\n",
    "\n",
    "The clarification follows President Bola Tinubu‚Äôs recent declaration of a state of emergency in Rivers State, which led to the six-month suspension of Governor Siminalayi Fubara, his deputy, and elected members of the State House of Assembly.\n",
    "\n",
    "NGF‚Äôs Position on Political Development\n",
    "\n",
    "Although the NGF did not directly reference the situation in Rivers, the statement signed by Dr Abdulateef Shittu, its Director General, stated that the forum is focused on governance and policy matters rather than partisan conflicts.\n",
    "\n",
    "‚ÄúThe Nigeria Governors‚Äô Forum (NGF) has received media inquiries requesting it to comment on some recent political developments in the country,‚Äù the statement read.\n",
    "Related News\n",
    "\n",
    "    Why democracy has failed in Africa ‚Äì Obasanjo\n",
    "    I never apologised for speaking my truth, Natasha disowns apology reports\n",
    "    Peter Obi condemns Rivers State fund release, urges respect for Rule of Law\n",
    "\n",
    "‚ÄúThe Forum wishes to clarify that it is an umbrella body for subnational governments, aimed at promoting unified policy positions and collaborating with relevant stakeholders in pursuit of sustainable socioeconomic growth and the well-being of the people.\n",
    "\n",
    "‚ÄúAs a technical and policy hub comprising governors elected on different platforms, the body elects to steer clear of taking positions that may alienate members with varying political interests.‚Äù\n",
    "\n",
    "Shittu noted that past political divisions within the forum have threatened its unity, making it essential to avoid controversial political stances.\n",
    "\n",
    "However, he assured Nigerians that the NGF remains committed to governance issues affecting economic growth and public welfare.\n",
    "\n",
    "‚ÄúRegardless, the Forum is known for its bold positions on governance and general policy matters of profound consequence, such as wages, taxes, education, and universal healthcare, among others,‚Äù Shittu stated.\n",
    "\n",
    "The NGF called for media and public understanding, expressing confidence that existing political institutions and crisis resolution mechanisms would address partisan disputes. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Extract named entities\n",
    "doc = nlp(news_text)\n",
    "entities = \" \".join([ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"GPE\", \"PERSON\"]])\n",
    "\n",
    "# Reliable news sources\n",
    "reliable_sources = [\n",
    "    \"punchng.com\", \"vanguardngr.com\", \"guardian.ng\", \"premiumtimesng.com\",\n",
    "    \"dailypost.ng\", \"thenationonlineng.net\", \"saharareporters.com\", \"channelstv.com\",\n",
    "    \"naijanews.com\", \"tribuneonlineng.com\", \"pmnewsnigeria.com\", \"sunnewsonline.com\",\n",
    "    \"leadership.ng\", \"dailytrust.com\", \"thisdaylive.com\", \"businessday.ng\",\n",
    "    \"independent.ng\", \"blueprint.ng\", \"thecable.ng\", \"nigerianbulletin.com\",\n",
    "    \"today.ng\", \"newtelegraphng.com\", \"tvcnews.tv\", \"nigerianeye.com\",\n",
    "    \"thestreetjournal.org\", \"pulseng.com\", \"newsdirect.ng\", \"nigerianmonitor.com\",\n",
    "    \"insidebusiness.ng\", \"businesspost.ng\", \"economicconfidential.com\", \"financialwatchngr.com\",\n",
    "    \"legit.ng\", \"newsdiaryonline.com\", \"nationalaccordnewspaper.com\", \"brandspurng.com\",\n",
    "    \"techcabal.com\", \"nigerianstoday.com\", \"plustvafrica.com\", \"thewhistler.ng\",\n",
    "    \"metrobusinessnews.com\", \"concisenews.global\", \"leadershipnigeria.com\",\n",
    "    \"realnewsmagazine.net\", \"thebossnewspapers.com\", \"orientdailynews.com\",\n",
    "    \"theeagleonline.com.ng\", \"nigeriatoday.ng\", \"aljazirahnews.com\", \"orderpaper.ng\",\n",
    "    \"brandpowerng.com\", \"newsherald.com.ng\", \"theabujatimes.com\", \"verbatimnews.com.ng\",\n",
    "    \"nigerianews.net\", \"politicsnigeria.com\", \"thestatesman.com.ng\", \"theyesng.com\",\n",
    "    \"notablenigeria.com\", \"thepointng.com\", \"forefrontng.com\", \"elanzanews.ng\",\n",
    "    \"nationaldailyng.com\", \"ecomarketafrica.com\", \"technext.ng\", \"newsverge.com\",\n",
    "    \"sciencenigeria.com\", \"nigeriahealthwatch.com\", \"nigerianinsidernews.com\",\n",
    "    \"alreporter.com\", \"thestandard.ng\", \"thespellng.com\", \"newsarena.com.ng\",\n",
    "    \"sahelstandard.com\", \"nigeriannewspapers.today\", \"sunrisenews.com.ng\",\n",
    "    \"businesselitesafrica.com\", \"thedefenderngr.com\", \"ikengaonline.com\",\n",
    "    \"energytimesng.com\", \"thealvinreport.com\", \"newnigeriannewspaper.com\",\n",
    "    \"technopreneur.com.ng\", \"thetrumpet.ng\", \"theanalyst.com.ng\",\n",
    "    \"realnewsnigeria.com\", \"thenewsnigeria.com.ng\", \"nigerianpilot.com\",\n",
    "    \"newsbeam.com.ng\", \"edutorial.ng\", \"mediacouncilnigeria.com\",\n",
    "    \"viewpointnigeria.com\", \"technotren.com\", \"huhuonline.com\",\n",
    "    \"nigeriatopnews.com\", \"thedaily-ng.com\", \"theimpactnewspaper.com\",\n",
    "    \"mynewswatchtimesng.com\", \"nairametrics.com\"\n",
    "]\n",
    "\n",
    "\n",
    "# Search API credentials\n",
    "search_api_key = \"SEARCH_API_KEY\"\n",
    "search_api_url = f\"https://www.searchapi.io/api/v1/search?q={entities}&engine=google_news\"\n",
    "search_headers = {\"Authorization\": f\"Bearer {search_api_key}\"}\n",
    "\n",
    "# Perform search request\n",
    "response_search = requests.get(search_api_url, headers=search_headers)\n",
    "search_results = response_search.json()\n",
    "\n",
    "# Check for reliability\n",
    "fake_news = True\n",
    "if \"organic_results\" in search_results:\n",
    "    for result in search_results.get(\"organic_results\", []):\n",
    "        if any(source in result.get(\"link\", \"\") for source in reliable_sources):\n",
    "            fake_news = False\n",
    "            break\n",
    "\n",
    "# Tavily API credentials\n",
    "tavily_api_key = \"TAVILY_API_KEY\"\n",
    "tavily_url = \"https://api.tavily.com/search\"\n",
    "tavily_payload = {\"api_key\": tavily_api_key, \"query\": entities, \"search_depth\": \"basic\", \"num_results\": 5}\n",
    "\n",
    "# Perform Tavily search request\n",
    "response_tavily = requests.post(tavily_url, json=tavily_payload)\n",
    "tavily_results = response_tavily.json()\n",
    "\n",
    "# Validate Tavily results\n",
    "if \"results\" in tavily_results:\n",
    "    for result in tavily_results.get(\"results\", []):\n",
    "        if any(source in result.get(\"url\", \"\") for source in reliable_sources):\n",
    "            fake_news = False\n",
    "            break\n",
    "\n",
    "# Final verdict\n",
    "print(\"‚úÖ Verified News: Found in reliable sources\" if not fake_news else \"‚ö†Ô∏è Likely Fake News: No reliable sources found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verified News: Found in reliable sources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import spacy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load NLP model for named entity recognition (NER)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# News article to verify\n",
    "news_text = \"\"\" Nigerian governors‚Äô forum breaks silence on Fubara‚Äôs suspension\n",
    "\n",
    "Tolulope Popoola\n",
    "\n",
    "March 22, 2025\n",
    "Nigerian Governors‚Äô Forum\n",
    "Share\n",
    "\n",
    "The Nigeria Governors‚Äô Forum (NGF) has defended its decision to remain silent on recent political events, emphasizing its role as a neutral policy body.\n",
    "\n",
    "In a statement issued on Saturday, titled ‚ÄúNGF Clarifies Silence on Political Matters,‚Äù the forum explained that taking positions on partisan issues could divide its members, who belong to different political platforms.\n",
    "\n",
    "The clarification follows President Bola Tinubu‚Äôs recent declaration of a state of emergency in Rivers State, which led to the six-month suspension of Governor Siminalayi Fubara, his deputy, and elected members of the State House of Assembly.\n",
    "\n",
    "NGF‚Äôs Position on Political Development\n",
    "\n",
    "Although the NGF did not directly reference the situation in Rivers, the statement signed by Dr Abdulateef Shittu, its Director General, stated that the forum is focused on governance and policy matters rather than partisan conflicts.\n",
    "\n",
    "‚ÄúThe Nigeria Governors‚Äô Forum (NGF) has received media inquiries requesting it to comment on some recent political developments in the country,‚Äù the statement read.\n",
    "\n",
    "‚ÄúThe Forum wishes to clarify that it is an umbrella body for subnational governments, aimed at promoting unified policy positions and collaborating with relevant stakeholders in pursuit of sustainable socioeconomic growth and the well-being of the people.\n",
    "\n",
    "‚ÄúAs a technical and policy hub comprising governors elected on different platforms, the body elects to steer clear of taking positions that may alienate members with varying political interests.‚Äù\n",
    "\n",
    "Shittu noted that past political divisions within the forum have threatened its unity, making it essential to avoid controversial political stances.\n",
    "\n",
    "However, he assured Nigerians that the NGF remains committed to governance issues affecting economic growth and public welfare.\n",
    "\n",
    "‚ÄúRegardless, the Forum is known for its bold positions on governance and general policy matters of profound consequence, such as wages, taxes, education, and universal healthcare, among others,‚Äù Shittu stated.\n",
    "\n",
    "The NGF called for media and public understanding, expressing confidence that existing political institutions and crisis resolution mechanisms would address partisan disputes. \n",
    "\"\"\"\n",
    "\n",
    "# Extract named entities\n",
    "doc = nlp(news_text)\n",
    "entities = \" \".join([ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"GPE\", \"PERSON\"]])\n",
    "\n",
    "# Reliable news sources\n",
    "reliable_sources = [\n",
    "    \"punchng.com\", \"vanguardngr.com\", \"guardian.ng\", \"premiumtimesng.com\",\n",
    "    \"dailypost.ng\", \"thenationonlineng.net\", \"saharareporters.com\", \"channelstv.com\",\n",
    "    \"naijanews.com\", \"tribuneonlineng.com\", \"pmnewsnigeria.com\", \"sunnewsonline.com\",\n",
    "    \"leadership.ng\", \"dailytrust.com\", \"thisdaylive.com\", \"businessday.ng\",\n",
    "    \"independent.ng\", \"thecable.ng\", \"nigerianbulletin.com\", \"today.ng\",\n",
    "    \"newtelegraphng.com\", \"tvcnews.tv\", \"nigerianeye.com\", \"thestreetjournal.org\",\n",
    "    \"pulseng.com\", \"newsdirect.ng\", \"nigerianmonitor.com\", \"insidebusiness.ng\",\n",
    "    \"businesspost.ng\", \"economicconfidential.com\", \"financialwatchngr.com\",\n",
    "    \"legit.ng\", \"newsdiaryonline.com\", \"nationalaccordnewspaper.com\", \"brandspurng.com\",\n",
    "    \"techcabal.com\", \"nigerianstoday.com\", \"plustvafrica.com\", \"thewhistler.ng\"\n",
    "]\n",
    "\n",
    "# Load API keys from environment variables\n",
    "search_api_key = os.getenv(\"SEARCHAPI_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if not search_api_key or not tavily_api_key:\n",
    "    raise ValueError(\"Missing API keys. Please set SEARCHAPI_KEY and TAVILY_API_KEY in your .env file.\")\n",
    "\n",
    "# SearchAPI.io request\n",
    "search_api_url = \"https://www.searchapi.io/api/v1/search\"\n",
    "search_params = {\n",
    "    \"q\": entities,\n",
    "    \"engine\": \"google_news\",\n",
    "    \"api_key\": search_api_key\n",
    "}\n",
    "\n",
    "try:\n",
    "    response_search = requests.get(search_api_url, params=search_params)\n",
    "    response_search.raise_for_status()\n",
    "    search_results = response_search.json()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"‚ö†Ô∏è Error fetching SearchAPI.io results: {e}\")\n",
    "    search_results = {}\n",
    "\n",
    "# Tavily API request\n",
    "tavily_url = \"https://api.tavily.com/search\"\n",
    "tavily_payload = {\n",
    "    \"api_key\": tavily_api_key,\n",
    "    \"query\": entities,\n",
    "    \"search_depth\": \"basic\",\n",
    "    \"num_results\": 5\n",
    "}\n",
    "\n",
    "try:\n",
    "    response_tavily = requests.post(tavily_url, json=tavily_payload)\n",
    "    response_tavily.raise_for_status()\n",
    "    tavily_results = response_tavily.json()\n",
    "except requests.RequestException as e:\n",
    "    print(f\"‚ö†Ô∏è Error fetching Tavily results: {e}\")\n",
    "    tavily_results = {}\n",
    "\n",
    "# Function to check reliability\n",
    "def is_reliable(results, key):\n",
    "    if key in results:\n",
    "        for result in results.get(key, []):\n",
    "            url = result.get(\"link\") or result.get(\"url\", \"\")\n",
    "            if any(source in url for source in reliable_sources):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Determine if the news is fake\n",
    "is_fake_news = not (is_reliable(search_results, \"organic_results\") or is_reliable(tavily_results, \"results\"))\n",
    "\n",
    "# Final verdict\n",
    "print(\"‚úÖ Verified News: Found in reliable sources\" if not is_fake_news else \"‚ö†Ô∏è Likely Fake News: No reliable sources found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
